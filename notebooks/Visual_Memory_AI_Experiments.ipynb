{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Memory AI - Experiments & Analysis\n",
    "\n",
    "This notebook contains experiments, visualizations, and analysis for the Visual Memory AI project.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Imports](#setup)\n",
    "2. [Data Exploration](#data-exploration)\n",
    "3. [Model Training Experiments](#training)\n",
    "4. [Evaluation & Analysis](#evaluation)\n",
    "5. [Explainability Visualization](#explainability)\n",
    "6. [Similarity Search Analysis](#similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Custom imports\n",
    "from data.preprocess import LaMemPreprocessor, create_sample_dataset\n",
    "from data.dataloader import MemorabilityDataset, create_dataloaders\n",
    "from models.model import create_model, count_parameters\n",
    "from models.train import Trainer\n",
    "from explainability.gradcam import GradCAM, visualize_memorability\n",
    "from similarity.search import SimilaritySearchEngine\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration <a name=\"data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for demonstration\n",
    "create_sample_dataset(output_dir=\"../data/lamem\", n_samples=1000)\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_csv(\"../data/lamem/metadata.csv\")\n",
    "print(f\"Dataset size: {len(df)} images\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memorability score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['memorability'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Memorability Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Memorability Scores')\n",
    "axes[0].axvline(df['memorability'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"memorability\"].mean():.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['memorability'], vert=True)\n",
    "axes[1].set_ylabel('Memorability Score')\n",
    "axes[1].set_title('Memorability Score Statistics')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df['memorability'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with different memorability scores\n",
    "def plot_sample_images(df, n_samples=6):\n",
    "    # Sort by memorability\n",
    "    df_sorted = df.sort_values('memorability')\n",
    "    \n",
    "    # Get extreme samples\n",
    "    low_mem = df_sorted.head(n_samples // 2)\n",
    "    high_mem = df_sorted.tail(n_samples // 2)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_samples // 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot low memorability\n",
    "    for i, (idx, row) in enumerate(low_mem.iterrows()):\n",
    "        img_path = f\"../data/lamem/images/{row['image_name']}\"\n",
    "        img = Image.open(img_path)\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f\"Low Mem: {row['memorability']:.3f}\")\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot high memorability\n",
    "    for i, (idx, row) in enumerate(high_mem.iterrows()):\n",
    "        img_path = f\"../data/lamem/images/{row['image_name']}\"\n",
    "        img = Image.open(img_path)\n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title(f\"High Mem: {row['memorability']:.3f}\")\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training Experiments <a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data splits\n",
    "preprocessor = LaMemPreprocessor()\n",
    "train_df, val_df, test_df = preprocessor.split_data(df)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_df, val_df, test_df,\n",
    "    \"../data/lamem/images\",\n",
    "    batch_size=16,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and inspect model\n",
    "model = create_model('resnet50', pretrained=True, device=device)\n",
    "\n",
    "print(f\"Total parameters: {count_parameters(model):,}\")\n",
    "print(f\"Model architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (reduced epochs for notebook)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    learning_rate=1e-4,\n",
    "    checkpoint_dir='../checkpoints',\n",
    "    log_dir='../logs'\n",
    ")\n",
    "\n",
    "history = trainer.train(num_epochs=10, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pearson correlation\n",
    "axes[1].plot(history['train_pearson'], label='Train Pearson', marker='o')\n",
    "axes[1].plot(history['val_pearson'], label='Val Pearson', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Pearson Correlation')\n",
    "axes[1].set_title('Training & Validation Correlation')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Analysis <a name=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, scores in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        ground_truth.extend(scores.numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "# Compute metrics\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "mse = np.mean((predictions - ground_truth) ** 2)\n",
    "pearson, _ = pearsonr(predictions, ground_truth)\n",
    "spearman, _ = spearmanr(predictions, ground_truth)\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test Pearson: {pearson:.4f}\")\n",
    "print(f\"Test Spearman: {spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Ground Truth\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(ground_truth, predictions, alpha=0.5, s=20)\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Ground Truth Memorability')\n",
    "plt.ylabel('Predicted Memorability')\n",
    "plt.title(f'Prediction vs Ground Truth (Pearson: {pearson:.3f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "errors = np.abs(predictions - ground_truth)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Absolute Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(errors.mean(), color='red', linestyle='--', label=f'Mean: {errors.mean():.3f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(ground_truth, errors, alpha=0.5, s=20)\n",
    "plt.xlabel('Ground Truth Memorability')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Error vs Ground Truth')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explainability Visualization <a name=\"explainability\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grad-CAM for sample images\n",
    "sample_images = test_df.sample(4)\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 14))\n",
    "\n",
    "for i, (idx, row) in enumerate(sample_images.iterrows()):\n",
    "    img_path = f\"../data/lamem/images/{row['image_name']}\"\n",
    "    \n",
    "    # Generate visualization\n",
    "    score, overlayed = visualize_memorability(\n",
    "        model, img_path, device=device\n",
    "    )\n",
    "    \n",
    "    # Original image\n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 0].set_title(f\"Original\\nTrue: {row['memorability']:.2f}\")\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Grad-CAM overlay\n",
    "    axes[i, 1].imshow(overlayed)\n",
    "    axes[i, 1].set_title(f\"Grad-CAM\\nPred: {score:.2f}\")\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Heatmap only\n",
    "    gradcam = GradCAM(model)\n",
    "    from torchvision import transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    heatmap = gradcam.generate_cam(img_tensor)\n",
    "    \n",
    "    axes[i, 2].imshow(heatmap, cmap='jet')\n",
    "    axes[i, 2].set_title(\"Heatmap\")\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Similarity Search Analysis <a name=\"similarity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build similarity search index\n",
    "search_engine = SimilaritySearchEngine(model, device=device)\n",
    "search_engine.build_index(\n",
    "    train_loader,\n",
    "    train_df['image_name'].tolist(),\n",
    "    save_path='../search_index.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity search\n",
    "query_sample = test_df.sample(1).iloc[0]\n",
    "query_path = f\"../data/lamem/images/{query_sample['image_name']}\"\n",
    "\n",
    "# Extract query embedding\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "query_img = Image.open(query_path).convert('RGB')\n",
    "query_tensor = transform(query_img).unsqueeze(0).to(device)\n",
    "query_emb = model.get_features(query_tensor).cpu().numpy()\n",
    "\n",
    "# Search for similar memorable images\n",
    "memorable_results = search_engine.search_by_memorability(\n",
    "    query_emb, memorable=True, top_k=3\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Query image\n",
    "axes[0].imshow(query_img)\n",
    "axes[0].set_title(f\"Query\\nMem: {query_sample['memorability']:.2f}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Similar memorable images\n",
    "for i, (idx, sim, mem) in enumerate(memorable_results):\n",
    "    img_path = f\"../data/lamem/images/{search_engine.image_paths[idx]}\"\n",
    "    img = Image.open(img_path)\n",
    "    axes[i+1].imshow(img)\n",
    "    axes[i+1].set_title(f\"Similar #{i+1}\\nMem: {mem:.2f}\\nSim: {sim:.2f}\")\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.suptitle('Similarity Search: Query vs Similar Memorable Images')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Data exploration and memorability distribution analysis\n",
    "2. Model training and performance tracking\n",
    "3. Comprehensive evaluation on test set\n",
    "4. Explainability through Grad-CAM visualizations\n",
    "5. Similarity search for finding comparable images\n",
    "\n",
    "Key findings:\n",
    "- Model achieves strong correlation with human memory scores\n",
    "- Grad-CAM reveals which visual features drive predictions\n",
    "- Similarity search successfully groups images by visual content\n",
    "\n",
    "Next steps:\n",
    "- Experiment with Vision Transformers\n",
    "- Hyperparameter tuning\n",
    "- Cross-dataset evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}